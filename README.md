### Objectif du Projet
CrÃ©er un pipeline dans Azure Data Factory qui copie les donnÃ©es depuis un fichier 
CSV (dans Azure Blob Storage) vers une table dans Azure SQL Database.

## ğŸ§± Ã‰tapes du projet :

# âœ… Ã‰tape 1 â€“ CrÃ©er le service Azure Data Factory :

Aller dans le portail Azure.
Cliquer sur "Create a Resource", chercher Data Factory.
Remplir les champs :
  Nom de la Data Factory
  Subscription
  Resource Group
  RÃ©gion
Lancer la crÃ©ation.
Une fois dÃ©ployÃ©e, cliquer sur "Author & Monitor" pour ouvrir lâ€™interface de crÃ©ation de pipelines.


# âœ… Ã‰tape 2 â€“ PrÃ©parer les ressources de stockage et base de donnÃ©es :

Uploader le fichier cars.csv dans un container Azure Blob Storage.
CrÃ©er une table Cars dans Azure SQL Database avec cette structure :
 
  CREATE TABLE Cars (
  Make NVARCHAR(50),
  Model NVARCHAR(50),
  Type NVARCHAR(50),
  Origin NVARCHAR(50),
  DriveTrain NVARCHAR(50),
  Length FLOAT
);

Sâ€™assurer que le firewall du serveur SQL autorise les connexions de services Azure (sinon le pipeline Ã©chouera).



# âœ… Ã‰tape 3 â€“ CrÃ©er les Linked Services :

Les connexions vers les sources/destinations de donnÃ©es.
Aller dans lâ€™onglet Manage > Linked services.
CrÃ©er un Linked Service pour :
  Azure Blob Storage (avec account key ou SAS token)
  Azure SQL Database (avec login/mot de passe SQL)


# âœ… Ã‰tape 4 â€“ CrÃ©er les Datasets : 
ReprÃ©sentation des donnÃ©es sources et cibles.
1- Dataset source (CSV dans Blob Storage):
Type : Azure Blob Storage > DelimitedText
SÃ©lectionner le fichier cars.csv
Cocher "First row as header"
Lier au Linked Service Blob Storage

2- Dataset cible (table dans Azure SQL):
Type : Azure SQL Database
SÃ©lectionner la table Cars
Lier au Linked Service SQL


# âœ… Ã‰tape 5 â€“ CrÃ©er la pipeline :

Aller dans lâ€™onglet Author > Pipelines > "New pipeline".
Donner un nom Ã  la pipeline : ex. CopyCarsPipeline.


# âœ… Ã‰tape 6 â€“ Ajouter une Copy Data Activity :
Lâ€™Ã©lÃ©ment central du pipeline.

Faire glisser une Copy Data activity dans le canevas.
Dans les propriÃ©tÃ©s :
  Source : sÃ©lectionner le dataset Blob (CSV)
  Sink : sÃ©lectionner le dataset SQL
Dans lâ€™onglet Mapping :
  VÃ©rifier que les colonnes sont bien mappÃ©es automatiquement (sinon le faire manuellement).


# âœ… Ã‰tape 7 â€“ ExÃ©cuter le pipeline :
Cliquer sur Debug pour tester immÃ©diatement.
Aller dans lâ€™onglet Monitor pour voir lâ€™Ã©tat dâ€™exÃ©cution.
VÃ©rifier que lâ€™activitÃ© est marquÃ©e comme Success.

# âœ… Ã‰tape 8 â€“ VÃ©rifier les donnÃ©es dans la base SQL :
Ouvrir le portail SQL ou utiliser Azure Query Editor.
Lancer : SELECT * FROM Cars;
VÃ©rifier que les lignes du fichier cars.csv ont bien Ã©tÃ© insÃ©rÃ©es dans la table.




## ğŸ§  RÃ©sultat :
âœ” Le pipeline fonctionne. Ã€ chaque exÃ©cution :
  Il lit le fichier cars.csv dans Azure Blob.
  Il copie les donnÃ©es dans la table Cars de Azure SQL DB.
  Le tout sans Ã©crire une seule ligne de code, via lâ€™interface graphique dâ€™ADF.





















